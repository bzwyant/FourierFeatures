{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e58322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "from dataio import ImageFitting, EncodedImageFitting\n",
    "from models import Siren, HybridSiren, MLP\n",
    "from training import train_inr\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97057ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument('--input', type=str, default='data/kodak/kodim24.png')\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--epochs', type=int, default=500)\n",
    "parser.add_argument('--epochs_til_summary', type=int, default=25)\n",
    "parser.add_argument('--batch_size', type=int, default=64*64)\n",
    "parser.add_argument('--normalization', type=bool, default=False)\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--model', type=str, default='siren')\n",
    "parser.add_argument(\"--siren_layers\", type=list[int], default=[0,1])\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe58d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datasets = {}\n",
    "\n",
    "img_fitting = ImageFitting(args.input, args.normalization)\n",
    "siren = Siren(in_features=2, \n",
    "              out_features=3, \n",
    "              hidden_features=256, \n",
    "              num_hidden_layers=4\n",
    "              ).to(device)\n",
    "model_datasets['siren'] = (siren, img_fitting.copy())\n",
    "\n",
    "for i in range(4):\n",
    "    siren_layers = np.arange(i)\n",
    "    hybrid_siren = HybridSiren(in_features=2,\n",
    "                        out_features=3, \n",
    "                        hidden_features=256, \n",
    "                        num_hidden_layers=4,\n",
    "                        siren_layers=siren_layers\n",
    "                        ).to(device)\n",
    "    model_datasets[f'hybrid_{str(siren_layers)}'] = (hybrid_siren, img_fitting.copy())\n",
    "\n",
    "gaussian_encoded_img_fitting = EncodedImageFitting(args.input, args.normalization, encoding_type='gaussian')\n",
    "mlp_gaussian = MLP(in_features=gaussian_encoded_img_fitting.encoding_dim,\n",
    "          out_features=3, \n",
    "          hidden_features=256, \n",
    "          num_hidden_layers=4\n",
    "          ).to(device)\n",
    "model_datasets['gaussian_ff_mlp'] = (mlp_gaussian, gaussian_encoded_img_fitting)\n",
    "\n",
    "fourier_encoded_img_fitting = EncodedImageFitting(args.input, args.normalization, encoding_type='basic', include_original=True)\n",
    "mlp_basic_fourier = MLP(in_features=fourier_encoded_img_fitting.encoding_dim,\n",
    "          out_features=3, \n",
    "          hidden_features=256, \n",
    "          num_hidden_layers=4\n",
    "          ).to(device)\n",
    "model_datasets['basic_ff_mlp'] = (mlp_basic_fourier, fourier_encoded_img_fitting)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = {}\n",
    "\n",
    "for model_name, (model, img_fitting) in model_datasets.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    print(summary(model, input_size=(1, 2), device=device))\n",
    "    \n",
    "    training_results[model_name] = train_inr(\n",
    "        model=model,\n",
    "        dataset=img_fitting,\n",
    "        optimizer=optimizer,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        epochs_til_summary=args.epochs_til_summary,\n",
    "        device=device\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
